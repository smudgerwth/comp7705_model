
(project) aidan@Aidans-MacBook-Air COMP7705 % python insurance_model_no_children.py 
Loading and preprocessing data...
Building model...

Starting training...
Epoch  Loss       RegLoss    ClsLoss    Acc     LR       
--------------------------------------------------------
  1  6145.0986  12289.8467     0.3576   0.845  1.00e-03
  2  1600.9249  3201.5198     0.3320   0.855  1.00e-03
  3  1556.7092  3113.0945     0.3232   0.857  1.00e-03
  4  1506.5782  3012.8389     0.3204   0.858  1.00e-03
  5  1451.8760  2903.4314     0.3187   0.859  1.00e-03
  6  1374.1143  2747.9058     0.3173   0.860  1.00e-03
  7  1342.9938  2685.6731     0.3154   0.859  1.00e-03
  8  1254.5266  2508.7395     0.3134   0.861  1.00e-03
  9  1221.2112  2442.1130     0.3123   0.861  1.00e-03
 10  1204.0612  2407.8098     0.3112   0.862  1.00e-03
 11  1187.0615  2373.8132     0.3101   0.863  1.00e-03
 12  1175.0010  2349.6895     0.3091   0.864  1.00e-03
 13  1152.4584  2304.6111     0.3055   0.865  1.00e-03
 14  1135.7990  2271.2896     0.3064   0.865  1.00e-03
 15  1112.0112  2223.7180     0.3050   0.865  1.00e-03
 16  1103.1517  2205.9993     0.3042   0.865  1.00e-03
 17  1096.9276  2193.5520     0.3033   0.867  1.00e-03
 18  1087.6984  2175.0945     0.3019   0.866  1.00e-03
 19  1083.5516  2166.8027     0.3010   0.867  1.00e-03
 20  1073.1073  2145.9136     0.3002   0.867  1.00e-03
 21  1064.7911  2129.2827     0.2989   0.868  1.00e-03
 22  1064.8987  2129.5000     0.2980   0.868  1.00e-03
 23  1049.1339  2097.9692     0.2974   0.869  1.00e-03
 24  1049.6642  2099.0305     0.2972   0.869  1.00e-03
 25  1039.6134  2078.9299     0.2961   0.870  1.00e-03
 26  1036.3121  2072.3259     0.2964   0.869  1.00e-03
 27  1034.3121  2068.3274     0.2953   0.869  1.00e-03
 28  1028.5800  2056.8647     0.2934   0.871  1.00e-03
 29  1030.4834  2060.6753     0.2936   0.870  1.00e-03
 30  1024.2281  2048.1606     0.2924   0.870  1.00e-03
 31  1016.6340  2032.9778     0.2909   0.871  1.00e-03
 32  1017.5731  2034.8560     0.2908   0.871  1.00e-03
 33  1012.7833  2025.2772     0.2905   0.871  1.00e-03
 34  1013.6375  2026.9882     0.2899   0.872  1.00e-03
 35  1010.9654  2021.6404     0.2895   0.872  1.00e-03
 36  1000.8521  2001.4132     0.2887   0.872  1.00e-03
 37  1000.9258  2001.5664     0.2880   0.872  1.00e-03
 38   998.2382  1996.1890     0.2883   0.873  1.00e-03
 39   995.7308  1991.1740     0.2870   0.873  1.00e-03
 40   993.5650  1986.8444     0.2870   0.872  1.00e-03
 41   987.4009  1974.5153     0.2860   0.874  1.00e-03
 42   985.1361  1969.9843     0.2857   0.874  1.00e-03
 43   984.6875  1969.0884     0.2853   0.874  1.00e-03
 44   981.2499  1962.2166     0.2842   0.875  1.00e-03
 45   977.5408  1954.7946     0.2852   0.875  1.00e-03
 46   975.8274  1951.3726     0.2835   0.875  1.00e-03
 47   973.9456  1947.6088     0.2835   0.874  1.00e-03
 48   970.1726  1940.0640     0.2834   0.874  1.00e-03
 49   970.8830  1941.4840     0.2836   0.875  1.00e-03
 50   970.4835  1940.6840     0.2827   0.875  1.00e-03
 51   966.9557  1933.6290     0.2832   0.875  1.00e-03
 52   964.0991  1927.9176     0.2819   0.875  1.00e-03
 53   960.0893  1919.8951     0.2819   0.876  1.00e-03
 54   960.8721  1921.4634     0.2811   0.876  1.00e-03
 55   961.8675  1923.4568     0.2805   0.876  1.00e-03
 56   958.3355  1916.3894     0.2807   0.876  1.00e-03
 57   960.9725  1921.6650     0.2800   0.876  1.00e-03
 58   953.8694  1907.4615     0.2801   0.876  1.00e-03
 59   951.7903  1903.3011     0.2800   0.876  1.00e-03
 60   951.2625  1902.2452     0.2795   0.877  1.00e-03
 61   951.4745  1902.6710     0.2791   0.877  1.00e-03
 62   949.0053  1897.7310     0.2792   0.877  1.00e-03
 63   946.8356  1893.3934     0.2782   0.877  1.00e-03
 64   947.1463  1894.0122     0.2791   0.877  1.00e-03
 65   947.4196  1894.5601     0.2781   0.877  1.00e-03
 66   944.6709  1889.0660     0.2783   0.877  1.00e-03
 67   942.8776  1885.4756     0.2781   0.877  1.00e-03
 68   941.9017  1883.5272     0.2784   0.876  1.00e-03
 69   941.2097  1882.1414     0.2777   0.878  1.00e-03
 70   940.8304  1881.3818     0.2780   0.878  1.00e-03
 71   940.2944  1880.3088     0.2775   0.877  1.00e-03
 72   938.8016  1877.3254     0.2774   0.877  1.00e-03
 73   937.7342  1875.1938     0.2765   0.877  1.00e-03
 74   936.6165  1872.9561     0.2763   0.878  1.00e-03
 75   936.3183  1872.3594     0.2767   0.878  1.00e-03
 76   936.4431  1872.6080     0.2766   0.878  1.00e-03
 77   929.3343  1858.3916     0.2765   0.877  1.00e-03
 78   932.2684  1864.2590     0.2765   0.878  1.00e-03
 79   931.6627  1863.0486     0.2761   0.878  1.00e-03
 80   928.2034  1856.1302     0.2760   0.878  1.00e-03
 81   928.8923  1857.5120     0.2760   0.878  1.00e-03
 82   928.6866  1857.0980     0.2755   0.878  1.00e-03
 83   929.7181  1859.1610     0.2759   0.878  5.00e-04
 84   921.3691  1842.4642     0.2732   0.879  5.00e-04
 85   920.3952  1840.5156     0.2732   0.879  5.00e-04
 86   921.2254  1842.1761     0.2729   0.879  5.00e-04
 87   918.4563  1836.6429     0.2733   0.879  5.00e-04
 88   917.9084  1835.5428     0.2725   0.879  5.00e-04
 89   917.8931  1835.5140     0.2724   0.879  5.00e-04
 90   915.5728  1830.8732     0.2720   0.879  5.00e-04
 91   915.4525  1830.6332     0.2722   0.879  5.00e-04
 92   914.8716  1829.4706     0.2718   0.879  5.00e-04
 93   914.7202  1829.1676     0.2715   0.880  5.00e-04
 94   914.7794  1829.2876     0.2717   0.880  5.00e-04
 95   917.1537  1834.0345     0.2722   0.880  5.00e-04
 96   910.8404  1821.4098     0.2722   0.879  5.00e-04
 97   912.7425  1825.2094     0.2720   0.879  5.00e-04
 98   910.7615  1821.2488     0.2719   0.880  5.00e-04
 99   910.0427  1819.8173     0.2714   0.880  5.00e-04
100   911.2851  1822.2972     0.2712   0.880  5.00e-04

Evaluating model...

Regression Metrics:
MAE: $1450.46
MSE: $3700560.54
RMSE: $1923.68

Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91      9909
           1       0.88      0.83      0.85     10106
           2       0.81      0.91      0.86      9927
           3       0.92      0.91      0.92     10058

    accuracy                           0.88     40000
   macro avg       0.89      0.88      0.88     40000
weighted avg       0.89      0.88      0.88     40000


Model saved successfully in Keras format!
(project) aidan@Aidans-MacBook-Air COMP7705 % 